{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0Df5TBM8P5p"
      },
      "source": [
        "use myenv for GLIDE and conda base for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA8wvr2n8P5r"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/eliohead/glide-finetune\n",
        "!cd glide-finetune/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r00RfGqp8P5r"
      },
      "outputs": [],
      "source": [
        "!pip install -r \"C:\\Users\\Babak\\Desktop\\Final_Glide_Project\\glide-finetune\\requirements.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41nVWq2m8P5r"
      },
      "outputs": [],
      "source": [
        "!pip install webdataset==0.1.103"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhg-Yi2O8P5s"
      },
      "outputs": [],
      "source": [
        "!python glide-finetune/train_glide.py \\\n",
        "  --epochs 30 \\\n",
        "  --use_captions \\\n",
        "  --project_name 'finetune1' \\\n",
        "  --batch_size 1 \\\n",
        "  --learning_rate 1e-06 \\\n",
        "  --side_x 128 \\\n",
        "  --side_y 128 \\\n",
        "  --resize_ratio 1.0 \\\n",
        "  --uncond_p 0.0 \\\n",
        "  --test_prompt \"benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses\" \\\n",
        "  --checkpoints_dir \"Checkpoint/April/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZpWuGH48P5s"
      },
      "outputs": [],
      "source": [
        "#for resume checkpoint\n",
        "!python glide-finetune/train_glide.py \\\n",
        "  --epochs 30 \\\n",
        "  --use_captions \\\n",
        "  --project_name 'finetune1' \\\n",
        "  --batch_size 4 \\\n",
        "  --learning_rate 1e-03 \\\n",
        "  --side_x 128 \\\n",
        "  --side_y 128 \\\n",
        "  --resize_ratio 1.0 \\\n",
        "  --uncond_p 0.0 \\\n",
        "  --resume_ckpt \"Checkpoint\\April\\glide-ft-1x10014.pt\" \\\n",
        "  --test_prompt \"benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses\" \\\n",
        "  --checkpoints_dir \"Checkpoint/April/April2/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMNq7K_V8P5s"
      },
      "outputs": [],
      "source": [
        "#upsampler train\n",
        "!python glide-finetune/train_glide.py \\\n",
        "  --train_upsample \\\n",
        "  --epochs 20 \\\n",
        "  --project_name 'finetune1' \\\n",
        "  --learning_rate 1e-06 \\\n",
        "  --side_x 64 \\\n",
        "  --side_y 64 \\\n",
        "  --uncond_p 0.0 \\\n",
        "  --resume_ckpt \"Checkpoint\\upsampler_train_2\\glide-ft-16x5000.pt\" \\\n",
        "  --test_prompt \"benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses\" \\\n",
        "  --checkpoints_dir \"Checkpoint/upsampler_train_3/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUfk5XRo8P5s"
      },
      "outputs": [],
      "source": [
        "!wandb login --relogin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unEJrEAE8P5s"
      },
      "outputs": [],
      "source": [
        "!wandb login 27e17dd8c6441bd9a526fc2dd8d4483a72dac678"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqs5MHjO8P5t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddbmw_Pz8P5t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJzjS5z68P5t"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "\n",
        "from glide_text2im.clip.model_creation import create_clip_model\n",
        "from glide_text2im.download import load_checkpoint\n",
        "from glide_text2im.model_creation import (\n",
        "    create_model_and_diffusion,\n",
        "    model_and_diffusion_defaults,\n",
        "    model_and_diffusion_defaults_upsampler,\n",
        ")\n",
        "from glide_text2im.tokenizer.simple_tokenizer import SimpleTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLlrwZOE8P5t"
      },
      "outputs": [],
      "source": [
        "#@title Device setup\n",
        "# This notebook supports both CPU and GPU.\n",
        "# On CPU, generating one sample may take on the order of 20 minutes.\n",
        "# On a GPU, it should be under a minute.\n",
        "\n",
        "has_cuda = th.cuda.is_available()\n",
        "device = th.device('cpu' if not has_cuda else 'cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nG23fmMu8P5t"
      },
      "outputs": [],
      "source": [
        "# Sampling parameters\n",
        "prompt = \"Actinic keratoses and intraepithelial carcinoma / Bowen's disease\" #@param {type:\"string\"}\n",
        "batch_size =  1 #@param {type:\"number\"}\n",
        "guidance_scale =  8#@param {type:\"number\"}\n",
        "\n",
        "#@markdown `upsample_temp` Tune this parameter to control the sharpness of 256x256 images.\n",
        "# A value of 1.0 is sharper, but sometimes results in grainy artifacts.\n",
        "upsample_temp = 1.0\n",
        "\n",
        "base_timestep_respacing = '40' #@param {type:\"string\"}\n",
        "\n",
        "sr_timestep_respacing = 'fast27'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULQERdxK8P5u"
      },
      "outputs": [],
      "source": [
        "#@title Create base model.\n",
        "glide_path = 'Checkpoint\\day3\\glide-ft-13x625.pt' #@param {type:\"string\"}\n",
        "import os\n",
        "options = model_and_diffusion_defaults()\n",
        "options['use_fp16'] = has_cuda\n",
        "options['timestep_respacing'] = base_timestep_respacing # use 100 diffusion steps for fast sampling\n",
        "model, diffusion = create_model_and_diffusion(**options)\n",
        "\n",
        "if len(glide_path) > 0:\n",
        "    assert os.path.exists(\n",
        "        glide_path\n",
        "    ), f\"Failed to resume from {glide_path}, file does not exist.\"\n",
        "    weights = th.load(glide_path, map_location=\"cpu\")\n",
        "    model, diffusion = create_model_and_diffusion(**options)\n",
        "    model.load_state_dict(weights)\n",
        "    print(f\"Resumed from {glide_path} successfully.\")\n",
        "else:\n",
        "    model, diffusion = create_model_and_diffusion(**options)\n",
        "    model.load_state_dict(load_checkpoint(\"base\", device))\n",
        "model.eval()\n",
        "if has_cuda:\n",
        "    model.convert_to_fp16()\n",
        "model.to(device)\n",
        "print('total base parameters', sum(x.numel() for x in model.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWeFiX_Y8P5u"
      },
      "outputs": [],
      "source": [
        "#@title Create upsampler model.\n",
        "sr_glide_path = r\"Checkpoint\\upsampler_train_3\\glide-ft-16x5000.pt\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "options_up = model_and_diffusion_defaults_upsampler()\n",
        "options_up['use_fp16'] = has_cuda\n",
        "options_up['timestep_respacing'] = sr_timestep_respacing # use 27 diffusion steps for very fast sampling\n",
        "\n",
        "if len(sr_glide_path) > 0:\n",
        "    assert os.path.exists(\n",
        "        sr_glide_path\n",
        "    ), f\"Failed to resume from {sr_glide_path}, file does not exist.\"\n",
        "    weights = th.load(sr_glide_path, map_location=\"cpu\")\n",
        "    model_up, diffusion_up = create_model_and_diffusion(**options_up)\n",
        "    model_up.load_state_dict(weights)\n",
        "    print(f\"Resumed from {sr_glide_path} successfully.\")\n",
        "else:\n",
        "    model_up, diffusion_up = create_model_and_diffusion(**options)\n",
        "    model_up.load_state_dict(load_checkpoint(\"upsample\", device))\n",
        "\n",
        "if has_cuda:\n",
        "    model_up.convert_to_fp16()\n",
        "model_up.to(device)\n",
        "print('total upsampler parameters', sum(x.numel() for x in model_up.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jD7DDaId8P5u"
      },
      "outputs": [],
      "source": [
        "#@title Util\n",
        "def show_images(batch: th.Tensor):\n",
        "    \"\"\" Display a batch of images inline. \"\"\"\n",
        "    scaled = ((batch + 1)*127.5).round().clamp(0,255).to(th.uint8).cpu()\n",
        "    reshaped = scaled.permute(2, 0, 3, 1).reshape([batch.shape[2], -1, 3])\n",
        "    display(Image.fromarray(reshaped.numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu4wIobt8P5u"
      },
      "outputs": [],
      "source": [
        "#@title Base model sampling\n",
        "##############################\n",
        "# Sample from the base model #\n",
        "##############################\n",
        "# Create the text tokens to feed to the model.\n",
        "\n",
        "tokens = model.tokenizer.encode(prompt)\n",
        "tokens, mask = model.tokenizer.padded_tokens_and_mask(\n",
        "    tokens, options[\"text_ctx\"]\n",
        ")\n",
        "uncond_tokens, uncond_mask = model.tokenizer.padded_tokens_and_mask(\n",
        "    [], options[\"text_ctx\"]\n",
        ")\n",
        "model_kwargs = dict(\n",
        "    tokens=th.tensor(\n",
        "        [tokens] * batch_size + [uncond_tokens] * batch_size, device=device\n",
        "    ),\n",
        "    mask=th.tensor(\n",
        "        [mask] * batch_size + [uncond_mask] * batch_size,\n",
        "        dtype=th.bool,\n",
        "        device=device,\n",
        "    ),\n",
        ")\n",
        "\n",
        "def cfg_model_fn(x_t, ts, **kwargs):\n",
        "    half = x_t[: len(x_t) // 2]\n",
        "    combined = th.cat([half, half], dim=0)\n",
        "    model_out = model(combined, ts, **kwargs)\n",
        "    eps, rest = model_out[:, :3], model_out[:, 3:]\n",
        "    cond_eps, uncond_eps = th.split(eps, len(eps) // 2, dim=0)\n",
        "    half_eps = uncond_eps + guidance_scale * (cond_eps - uncond_eps)\n",
        "    eps = th.cat([half_eps, half_eps], dim=0)\n",
        "    return th.cat([eps, rest], dim=1)\n",
        "# Sample from the base model.\n",
        "\n",
        "\n",
        "full_batch_size = batch_size * 2\n",
        "model.del_cache()\n",
        "samples = diffusion.plms_sample_loop(\n",
        "    cfg_model_fn,\n",
        "    (full_batch_size, 3, options[\"image_size\"], options[\"image_size\"]),\n",
        "    device=device,\n",
        "    clip_denoised=True,\n",
        "    progress=True,\n",
        "    model_kwargs=model_kwargs,\n",
        "    cond_fn=None,\n",
        ")[:batch_size]\n",
        "model.del_cache()\n",
        "\n",
        "# Show the output\n",
        "show_images(samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5xrzOtq8P5u"
      },
      "outputs": [],
      "source": [
        "#@title Upsampling 4x\n",
        "\n",
        "##############################\n",
        "# Upsample the 64x64 samples #\n",
        "##############################\n",
        "\n",
        "tokens = model_up.tokenizer.encode(prompt)\n",
        "tokens, mask = model_up.tokenizer.padded_tokens_and_mask(\n",
        "    tokens, options_up['text_ctx']\n",
        ")\n",
        "\n",
        "# Create the model conditioning dict.\n",
        "model_kwargs = dict(\n",
        "    # Low-res image to upsample.\n",
        "    low_res=((samples+1)*127.5).round()/127.5 - 1,\n",
        "\n",
        "    # Text tokens\n",
        "    tokens=th.tensor(\n",
        "        [tokens] * batch_size, device=device\n",
        "    ),\n",
        "    mask=th.tensor(\n",
        "        [mask] * batch_size,\n",
        "        dtype=th.bool,\n",
        "        device=device,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Sample from the base model.\n",
        "model_up.del_cache()\n",
        "up_shape = (batch_size, 3, options_up[\"image_size\"], options_up[\"image_size\"])\n",
        "up_samples = diffusion_up.plms_sample_loop(\n",
        "    model_up,\n",
        "    up_shape,\n",
        "    noise=th.randn(up_shape, device=device) * upsample_temp,\n",
        "    device=device,\n",
        "    clip_denoised=True,\n",
        "    progress=True,\n",
        "    model_kwargs=model_kwargs,\n",
        "    cond_fn=None,\n",
        ")[:batch_size]\n",
        "model_up.del_cache()\n",
        "\n",
        "# Show the output\n",
        "show_images(up_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWM__s-M8P5v"
      },
      "outputs": [],
      "source": [
        "size = 256, 256\n",
        "im = Image.open(\"HAM10000\\ISIC_0030817.jpg\")\n",
        "im_resized = im.resize(size, Image.ANTIALIAS)\n",
        "im_resized.save(\"Checkpoint/Image_resized/my_image_resized.png\", \"PNG\")\n",
        "\n",
        "size = 256, 256\n",
        "im = Image.open(\"HAM10000\\ISIC_0029470.jpg\")\n",
        "im_resized = im.resize(size, Image.ANTIALIAS)\n",
        "im_resized.save(\"Checkpoint/Image_resized/my_image_resized_2.png\", \"PNG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "el2oGuZ28P5v"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from PIL import Image\n",
        "\n",
        "images = [Image.open(x) for x in ['Checkpoint\\Image_resized\\my_image_resized_2.png', 'Checkpoint\\Image_resized\\my_image_resized.png']]\n",
        "widths, heights = zip(*(i.size for i in images))\n",
        "\n",
        "total_width = sum(widths)\n",
        "max_height = max(heights)\n",
        "\n",
        "new_im = Image.new('RGB', (total_width, max_height))\n",
        "\n",
        "x_offset = 0\n",
        "for im in images:\n",
        "  new_im.paste(im, (x_offset,0))\n",
        "  x_offset += im.size[0]\n",
        "\n",
        "new_im.save('Checkpoint/Image_resized/test.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ane2iVCg8P5v"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LOVVTKq8P5v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "base_folder = r\"C:\\Users\\Babak\\Desktop\\Final_Glide_Project\\HAM10000\"\n",
        "destination_folder = r\"C:\\Users\\Babak\\Desktop\\Final_Glide_Project\\Validation\"\n",
        "\n",
        "# Iterate over all .jpg files in the base_folder\n",
        "for img_path in glob.glob(os.path.join(base_folder, '*.jpg')):\n",
        "    # Extract the filename without the extension\n",
        "    filename = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    \n",
        "    # Create a subfolder in the destination_folder with the filename\n",
        "    subfolder_path = os.path.join(destination_folder, filename)\n",
        "    os.makedirs(subfolder_path, exist_ok=True)\n",
        "    \n",
        "    # Move the .jpg file and the corresponding .txt file to the subfolder\n",
        "    txt_path = os.path.join(base_folder, f\"{filename}.txt\")\n",
        "    shutil.move(img_path, os.path.join(subfolder_path, os.path.basename(img_path)))\n",
        "    shutil.move(txt_path, os.path.join(subfolder_path, os.path.basename(txt_path)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJCzPFEG8P5v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "# Define the path to the folder containing the subfolders with the images and prompts\n",
        "path = r'C:\\Users\\Babak\\Desktop\\Final_Glide_Project\\Validation'\n",
        "\n",
        "# Loop through all subfolders in the folder\n",
        "for folder_name in os.listdir(path):\n",
        "    folder_path = os.path.join(path, folder_name)\n",
        "\n",
        "    # Only process subfolders that contain a .jpg file and a .txt file\n",
        "    if os.path.isdir(folder_path) and \\\n",
        "        any(file.endswith('.jpg') for file in os.listdir(folder_path)) and \\\n",
        "        any(file.endswith('.txt') for file in os.listdir(folder_path)):\n",
        "\n",
        "        # Load the ground truth image\n",
        "        gt_image_path = os.path.join(folder_path, folder_name + '.jpg')\n",
        "        gt_image = Image.open(gt_image_path)\n",
        "\n",
        "        # Load the prompt\n",
        "        with open(os.path.join(folder_path, folder_name + '.txt'), 'r') as f:\n",
        "            prompt = f.read()\n",
        "\n",
        "        # Sample a synthetic image using the provided code\n",
        "        tokens = model.tokenizer.encode(prompt)\n",
        "        tokens, mask = model.tokenizer.padded_tokens_and_mask(\n",
        "            tokens, options[\"text_ctx\"]\n",
        "        )\n",
        "        uncond_tokens, uncond_mask = model.tokenizer.padded_tokens_and_mask(\n",
        "            [], options[\"text_ctx\"]\n",
        "        )\n",
        "        model_kwargs = dict(\n",
        "            tokens=th.tensor(\n",
        "                [tokens] * batch_size + [uncond_tokens] * batch_size, device=device\n",
        "            ),\n",
        "            mask=th.tensor(\n",
        "                [mask] * batch_size + [uncond_mask] * batch_size,\n",
        "                dtype=th.bool,\n",
        "                device=device,\n",
        "            ),\n",
        "        )\n",
        "        \n",
        "        def cfg_model_fn(x_t, ts, **kwargs):\n",
        "            half = x_t[: len(x_t) // 2]\n",
        "            combined = th.cat([half, half], dim=0)\n",
        "            model_out = model(combined, ts, **kwargs)\n",
        "            eps, rest = model_out[:, :3], model_out[:, 3:]\n",
        "            cond_eps, uncond_eps = th.split(eps, len(eps) // 2, dim=0)\n",
        "            half_eps = uncond_eps + guidance_scale * (cond_eps - uncond_eps)\n",
        "            eps = th.cat([half_eps, half_eps], dim=0)\n",
        "            return th.cat([eps, rest], dim=1)\n",
        "                # Sample from the base model.\n",
        "\n",
        "\n",
        "        full_batch_size = batch_size * 2\n",
        "        model.del_cache()\n",
        "        samples = diffusion.plms_sample_loop(\n",
        "            cfg_model_fn,\n",
        "            (full_batch_size, 3, options[\"image_size\"], options[\"image_size\"]),\n",
        "            device=device,\n",
        "            clip_denoised=True,\n",
        "            progress=True,\n",
        "            model_kwargs=model_kwargs,\n",
        "            cond_fn=None,\n",
        "        )[:batch_size]\n",
        "        model.del_cache()\n",
        "\n",
        "\n",
        "        #@title Upsampling 4x\n",
        "\n",
        "        ##############################\n",
        "        # Upsample the 64x64 samples #\n",
        "        ##############################\n",
        "\n",
        "        tokens = model_up.tokenizer.encode(prompt)\n",
        "        tokens, mask = model_up.tokenizer.padded_tokens_and_mask(\n",
        "            tokens, options_up['text_ctx']\n",
        "        )\n",
        "\n",
        "        # Create the model conditioning dict.\n",
        "        model_kwargs = dict(\n",
        "            # Low-res image to upsample.\n",
        "            low_res=((samples+1)*127.5).round()/127.5 - 1,\n",
        "\n",
        "            # Text tokens\n",
        "            tokens=th.tensor(\n",
        "                [tokens] * batch_size, device=device\n",
        "            ),\n",
        "            mask=th.tensor(\n",
        "                [mask] * batch_size,\n",
        "                dtype=th.bool,\n",
        "                device=device,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # Sample from the base model.\n",
        "        model_up.del_cache()\n",
        "        up_shape = (batch_size, 3, options_up[\"image_size\"], options_up[\"image_size\"])\n",
        "        up_samples = diffusion_up.plms_sample_loop(\n",
        "            model_up,\n",
        "            up_shape,\n",
        "            noise=th.randn(up_shape, device=device) * upsample_temp,\n",
        "            device=device,\n",
        "            clip_denoised=True,\n",
        "            progress=True,\n",
        "            model_kwargs=model_kwargs,\n",
        "            cond_fn=None,\n",
        "        )[:batch_size]\n",
        "        model_up.del_cache()\n",
        "\n",
        "\n",
        "        # Save the synthetic image to the subfolder with the name \"{folder_name}_synthetic.jpg\"\n",
        "        synthetic_image_path = os.path.join(folder_path, folder_name + '_synthetic.jpg')\n",
        "        save_image(\n",
        "            up_samples[0],\n",
        "            synthetic_image_path,\n",
        "            normalize=True,\n",
        "            range=(-1, 1),\n",
        "        )\n",
        "\n",
        "        # Resize the ground truth image to the size of the synthetic image and overwrite the current ground truth image\n",
        "        gt_image_resized = gt_image.resize((options_up[\"image_size\"], options_up[\"image_size\"]))\n",
        "        gt_image_resized.save(gt_image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1s6grv578P5v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "from scipy.linalg import sqrtm\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "import tensorflow as tf\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def mse(imageA, imageB):\n",
        "    return np.mean((imageA - imageB) ** 2)\n",
        "\n",
        "def psnr(imageA, imageB):\n",
        "    MSE = mse(imageA, imageB)\n",
        "    if MSE == 0:\n",
        "        return 100\n",
        "    max_pixel = 255.0\n",
        "    return 20 * np.log10(max_pixel / np.sqrt(MSE))\n",
        "\n",
        "def calculate_fid_score(act1, act2):\n",
        "    mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
        "    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
        "    ssdiff = np.sum((mu1 - mu2) ** 2.0)\n",
        "    covmean = sqrtm(sigma1.dot(sigma2))\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "    return fid\n",
        "\n",
        "def calculate_inception_score(activations, eps=1E-18):\n",
        "    p_yx = activations / np.sum(activations, axis=1, keepdims=True)  # Normalize the activations\n",
        "    p_y = np.expand_dims(np.mean(p_yx, axis=0), 0)\n",
        "    kl_d = p_yx * (np.log(p_yx + eps) - np.log(p_y + eps))\n",
        "    sum_kl_d = np.sum(kl_d, axis=1)\n",
        "    avg_kl_d = np.mean(sum_kl_d)\n",
        "    is_score = np.exp(np.clip(avg_kl_d, -700, 700))\n",
        "    return is_score\n",
        "\n",
        "def get_activations(images, model):\n",
        "    image_shape = (299, 299, 3)\n",
        "    images_resized = np.zeros((len(images), *image_shape))\n",
        "    for i in range(len(images)):\n",
        "        images_resized[i] = cv2.resize(images[i], image_shape[:2])\n",
        "    preprocessed_images = preprocess_input(images_resized)\n",
        "    activations = model.predict(preprocessed_images)\n",
        "    return activations\n",
        "\n",
        "def evaluate_images(real_imgs, synthetic_imgs, win_size=None):\n",
        "    ssim_vals = []\n",
        "    psnr_vals = []\n",
        "    mse_vals = []\n",
        "\n",
        "    for real_img, synthetic_img in zip(real_imgs, synthetic_imgs):\n",
        "        # Convert images to float32 dtype\n",
        "        real_img = real_img.astype(np.float32)\n",
        "        synthetic_img = synthetic_img.astype(np.float32)\n",
        "\n",
        "        # Normalize the pixel values to the range [0, 1] if they are not already normalized\n",
        "        real_img /= 255.0\n",
        "        synthetic_img /= 255.0\n",
        "\n",
        "        # Calculate SSIM separately for each channel and take the average\n",
        "        ssim_r = ssim(real_img[..., 0], synthetic_img[..., 0], win_size=win_size, data_range=1.0)\n",
        "        ssim_g = ssim(real_img[..., 1], synthetic_img[..., 1], win_size=win_size, data_range=1.0)\n",
        "        ssim_b = ssim(real_img[..., 2], synthetic_img[..., 2], win_size=win_size, data_range=1.0)\n",
        "        ssim_val = (ssim_r + ssim_g + ssim_b) / 3\n",
        "\n",
        "        ssim_vals.append(ssim_val)\n",
        "        psnr_vals.append(psnr(real_img, synthetic_img))\n",
        "        mse_r = mean_squared_error(real_img[..., 0].flatten(), synthetic_img[..., 0].flatten())\n",
        "        mse_g = mean_squared_error(real_img[..., 1].flatten(), synthetic_img[..., 1].flatten())\n",
        "        mse_b = mean_squared_error(real_img[..., 2].flatten(), synthetic_img[..., 2].flatten())\n",
        "        mse_vals.append(np.mean([mse_r, mse_g, mse_b]))\n",
        "\n",
        "    return np.mean(ssim_vals), np.mean(psnr_vals), np.mean(mse_vals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0yJFp9Q8P5v"
      },
      "outputs": [],
      "source": [
        "main_folder = \"C:/Users/Babak/Desktop/Final_Glide_Project/Validation\"\n",
        "subfolders = [f.path for f in os.scandir(main_folder) if f.is_dir()]\n",
        "\n",
        "entities = [\n",
        "    \"melanoma\", \"melanocytic nevi\", \"Actinic keratoses and intraepithelial carcinoma / Bowen's disease\", \"benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses\", \"basal cell carcinoma\", \"dermatofibroma\", \"vascular lesions (angiomas\"\n",
        "]\n",
        "\n",
        "entity_dict = {entity: [] for entity in entities}\n",
        "\n",
        "inception_model = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))\n",
        "\n",
        "for folder in subfolders:\n",
        "    ground_truth_path = os.path.join(folder, os.path.basename(folder) + \".jpg\")\n",
        "    synthetic_path = os.path.join(folder, os.path.basename(folder) + \"_synthetic.jpg\")\n",
        "    txt_path = os.path.join(folder, os.path.basename(folder) + \".txt\")\n",
        "\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        entity = f.readline().strip()\n",
        "\n",
        "    ground_truth = cv2.imread(ground_truth_path)\n",
        "    synthetic = cv2.imread(synthetic_path)\n",
        "    entity_dict[entity].append((ground_truth, synthetic))\n",
        "\n",
        "total_SSIM, total_PSNR, total_MSE, total_FID, total_IS = 0, 0, 0, 0, 0\n",
        "num_entities = 0\n",
        "\n",
        "# Calculate metrics for each entity\n",
        "for entity, image_pairs in entity_dict.items():\n",
        "    if len(image_pairs) == 0:\n",
        "        continue\n",
        "\n",
        "    num_entities += 1\n",
        "    real_images = [pair[0] for pair in image_pairs]\n",
        "    synthetic_images = [pair[1] for pair in image_pairs]\n",
        "    SSIM, PSNR, MSE = evaluate_images(real_images, synthetic_images, win_size=255)\n",
        "\n",
        "    real_activations = get_activations(real_images, inception_model)\n",
        "    synthetic_activations = get_activations(synthetic_images, inception_model)\n",
        "    FID = calculate_fid_score(real_activations, synthetic_activations)\n",
        "    inception_score = calculate_inception_score(synthetic_activations)\n",
        "\n",
        "    total_SSIM += SSIM\n",
        "    total_PSNR += PSNR\n",
        "    total_MSE += MSE\n",
        "    total_FID += FID\n",
        "    total_IS += inception_score\n",
        "\n",
        "    print(f'Metrics for {entity}:')\n",
        "    print(f'SSIM: {SSIM:.4f}')\n",
        "    print(f'PSNR: {PSNR:.4f}')\n",
        "    print(f'MSE: {MSE:.4f}')\n",
        "    print(f'FID: {FID:.4f}')\n",
        "    print(f'IS: {inception_score:.4f}')\n",
        "    print('\\n')\n",
        "\n",
        "# Calculate average metrics over all entities\n",
        "avg_SSIM = total_SSIM / num_entities\n",
        "avg_PSNR = total_PSNR / num_entities\n",
        "avg_MSE = total_MSE / num_entities\n",
        "avg_FID = total_FID / num_entities\n",
        "avg_IS = total_IS / num_entities\n",
        "\n",
        "# Print overall metrics\n",
        "print('Overall metrics:')\n",
        "print(f'Average SSIM: {avg_SSIM:.4f}')\n",
        "print(f'Average PSNR: {avg_PSNR:.4f}')\n",
        "print(f'Average MSE: {avg_MSE:.4f}')\n",
        "print(f'Average FID: {avg_FID:.4f}')\n",
        "print(f'Average IS: {avg_IS:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agdb88QS8P5w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Read the Excel file\n",
        "file_path = r\"C:\\Users\\Babak\\Desktop\\Final_Glide_Project\\comparison\\excel.xlsx\"\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Fill NaN values with 0\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# Extract true entity labels from the dataset\n",
        "y_true = df['entitiy'].values\n",
        "\n",
        "# Create a dictionary to map column names to their respective coding values\n",
        "entity_coding_map = {\n",
        "    \"melanoma\": 1,\n",
        "    \"melanocytic nevi\": 2,\n",
        "    \"Actinic keratoses and intraepithelial carcinoma / Bowens disease\": 3,\n",
        "    \"benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses\": 4,\n",
        "    \"basal cell carcinoma\": 5,\n",
        "    \"dermatofibroma\": 6,\n",
        "    \"vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage\": 7\n",
        "}\n",
        "\n",
        "# Extract the dermatologist's entity predictions\n",
        "entity_columns = list(entity_coding_map.keys())\n",
        "y_pred = df[entity_columns].idxmax(axis=1).apply(lambda x: entity_coding_map[x]).values\n",
        "\n",
        "# Extract the AI_generated and Original columns\n",
        "ai_generated_col = \"AI_Generated\"\n",
        "original_col = \"Original\"\n",
        "ai_generated_true = (df['ID'].str.startswith('AI')).astype(int).values\n",
        "ai_generated_pred = df[ai_generated_col].values\n",
        "\n",
        "# Metrics for AI-generated vs Original images\n",
        "print(\"AI-generated vs Original images evaluation:\")\n",
        "print(classification_report(ai_generated_true, ai_generated_pred))\n",
        "\n",
        "# Metrics for Entity classification\n",
        "print(\"Entity classification evaluation:\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Split the dataset into AI-generated and Original subsets\n",
        "df_ai_generated = df[df['ID'].str.startswith('AI')]\n",
        "df_original = df[~df['ID'].str.startswith('AI')]\n",
        "\n",
        "# Extract true entity labels for AI-generated and Original subsets\n",
        "y_true_ai_generated = df_ai_generated['entitiy'].values\n",
        "y_true_original = df_original['entitiy'].values\n",
        "\n",
        "# Extract the dermatologist's entity predictions for AI-generated and Original subsets\n",
        "y_pred_ai_generated = df_ai_generated[entity_columns].idxmax(axis=1).apply(lambda x: entity_coding_map[x]).values\n",
        "y_pred_original = df_original[entity_columns].idxmax(axis=1).apply(lambda x: entity_coding_map[x]).values\n",
        "\n",
        "# Metrics for Entity classification (AI-generated subset)\n",
        "print(\"Entity classification evaluation (AI-generated subset):\")\n",
        "print(classification_report(y_true_ai_generated, y_pred_ai_generated))\n",
        "\n",
        "# Metrics for Entity classification (Original subset)\n",
        "print(\"Entity classification evaluation (Original subset):\")\n",
        "print(classification_report(y_true_original, y_pred_original))\n",
        "\n",
        "# Confusion matrix for Entity classification\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=entity_columns, yticklabels=entity_columns)\n",
        "plt.title('Confusion Matrix for Entity Classification')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# Binarize the true and predicted labels\n",
        "y_true_bin = label_binarize(y_true, classes=range(1, 8))\n",
        "y_pred_bin = label_binarize(y_pred, classes=range(1, 8))\n",
        "\n",
        "# Compute ROC curve and ROC AUC for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(7): # Assuming there are 7 classes\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_bin[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curves for each entity\n",
        "plt.figure()\n",
        "lw = 2\n",
        "colors = ['darkorange', 'blue', 'green', 'red', 'purple', 'brown', 'cyan']\n",
        "for i, color in zip(range(7), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw, label='ROC curve of class {0} (area = {1:0.2f})'.format(i + 1, roc_auc[i]))\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (Entity Prediction)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Confusion matrix for AI-generated vs Original images\n",
        "cm_ai_generated = confusion_matrix(ai_generated_true, ai_generated_pred)\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.heatmap(cm_ai_generated, annot=True, fmt='d', cmap='Blues', xticklabels=['Original', 'AI-generated'], yticklabels=['Original', 'AI-generated'])\n",
        "plt.title('Confusion Matrix for AI-generated vs Original Classification')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve for AI-generated vs Original images\n",
        "fpr, tpr, _ = roc_curve(ai_generated_true, ai_generated_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (AI-generated vs Original)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xw5ceN4_8P5w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCzu-gZD8P5w"
      },
      "outputs": [],
      "source": [
        "def load_dataset(folder_path, image_size=(256, 256)):  # Change the default image_size to (256, 256)\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for folder in glob.glob(os.path.join(folder_path, '*')):\n",
        "        for img_path in glob.glob(os.path.join(folder, '*.jpg')):\n",
        "            img = Image.open(img_path).resize(image_size)\n",
        "            images.append(np.array(img))\n",
        "            if \"_synthetic\" not in img_path:\n",
        "                with open(img_path.replace('.jpg', '.txt'), 'r') as f:\n",
        "                    label = f.read().strip()\n",
        "            else:\n",
        "                # Assuming the label for the synthetic image is the same as the original image\n",
        "                with open(img_path.replace('_synthetic.jpg', '.txt'), 'r') as f:\n",
        "                    label = f.read().strip()\n",
        "            labels.append(label)\n",
        "\n",
        "    return np.array(images), labels\n",
        "\n",
        "folder_path = r\"C:\\Users\\Babak\\Desktop\\Final_Glide_Project\\Validation\"\n",
        "\n",
        "images, labels = load_dataset(folder_path)\n",
        "\n",
        "# Normalize the images\n",
        "images = images / 255.0\n",
        "\n",
        "# Encode the labels\n",
        "encoder = LabelEncoder()\n",
        "labels = encoder.fit_transform(labels)\n",
        "\n",
        "# Train-Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw3ADp3M8P5w"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1ov31dW8P5w"
      },
      "outputs": [],
      "source": [
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Create an EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# Train the model with the EarlyStopping callback\n",
        "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=100,\n",
        "                    callbacks=[early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biR9KNdx8P5w"
      },
      "outputs": [],
      "source": [
        "model.save('my_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2IqSUJz8P5w"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('my_model.h5')\n",
        "\n",
        "# Continue training\n",
        "history = model.fit(datagen.flow(X_train, y_train, batch_size=32), validation_data=(X_test, y_test), epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE_VQ11q8P5w"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqcJLirs8P5w"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Get predictions for the test set\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "# Calculate the metrics\n",
        "print(\"Model evaluation:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
        "plt.title('Confusion Matrix for Model')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "db65719e2cd38068fb162f529b3c38fe2f17c9d4e0d4e0f03391cb3bb08fe519"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}